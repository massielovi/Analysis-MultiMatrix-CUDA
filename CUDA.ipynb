{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvyRWCtR-a9h",
        "outputId": "fc3b704d-8c75-4309-9856-436f8c22727d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 16 19:17:31 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hjayjjz_nS1",
        "outputId": "3748916a-de23-4344-e0ba-e5463703aab4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjmWVtZeBoXH",
        "outputId": "f803d0b6-1209-4ae2-8217-aedfcb265ab6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-b_aoe6i1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-b_aoe6i1\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4294 sha256=374c0bbe7afdd88224f8884f57d33e6022a23d4a9c7e184d836327f610d28344\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-33f2f6r0/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section Chapter 2"
      ],
      "metadata": {
        "id": "66LulXzOCQsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-rjBKgVBxfW",
        "outputId": "2d17c74c-6be3-4d22-fd7d-75e84221d6d0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <device_launch_parameters.h>\n",
        "#include <iostream>\n",
        "\n",
        "__global__ void vectorAddKernel(const float* A, const float* B, float* C, int n)\n",
        "{\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "void vecAdd(float* A, float* B, float* C, int n)\n",
        "{\n",
        "    int size = n * sizeof(float);\n",
        "    float *d_A, *d_B, *d_C;\n",
        "\n",
        "    // Allocate device memory for A, B, and C\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "    cudaMalloc((void**)&d_C, size);\n",
        "\n",
        "    // Copy A and B to device memory\n",
        "    cudaMemcpy(d_A, A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define grid and block dimensions\n",
        "    int threadsPerBlock = 256;  // You can adjust this based on your GPU\n",
        "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    // Kernel launch code – to have the device perform the actual vector addition\n",
        "    vectorAddKernel<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, n);\n",
        "\n",
        "    // Copy C from the device memory\n",
        "    cudaMemcpy(C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Free device vectors\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int n = 10;  // You can change the size of the vectors as needed\n",
        "    float *A, *B, *C;\n",
        "\n",
        "    A = (float*)malloc(n * sizeof(float));\n",
        "    B = (float*)malloc(n * sizeof(float));\n",
        "    C = (float*)malloc(n * sizeof(float));\n",
        "\n",
        "    // Initialize A and B here\n",
        "\n",
        "    // Inicializa los vectores A y B\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        A[i] = static_cast<float>(i);  // Puedes cambiar estos valores\n",
        "        B[i] = static_cast<float>(2 * i);\n",
        "    }\n",
        "\n",
        "    vecAdd(A, B, C, n);\n",
        "\n",
        "    // Imprime los vectores A, B y el resultado C\n",
        "    std::cout << \"Vector A: \";\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        std::cout << A[i] << \" \";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    std::cout << \"Vector B: \";\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        std::cout << B[i] << \" \";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    std::cout << \"Resultado C: \";\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        std::cout << C[i] << \" \";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "\n",
        "\n",
        "\n",
        "    // C now contains the result of the vector addition\n",
        "\n",
        "    // Don't forget to free host memory when you're done\n",
        "    free(A);\n",
        "    free(B);\n",
        "    free(C);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAZlx6MEBz63",
        "outputId": "db968b09-5b7b-41e1-f8be-e8bb7a29862e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector A: 0 1 2 3 4 5 6 7 8 9 \n",
            "Vector B: 0 2 4 6 8 10 12 14 16 18 \n",
            "Resultado C: 0 3 6 9 12 15 18 21 24 27 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "if tf.test.gpu_device_name():\n",
        "    print('GPU encontrada:')\n",
        "    print(tf.test.gpu_device_name())\n",
        "else:\n",
        "    print('No se encontró una GPU. Asegúrate de que has habilitado el entorno de ejecución de GPU en el menú \"Entorno de ejecución\".')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEySqIPfGPjt",
        "outputId": "ce2bd189-fd74-4a28-c80d-f4b44a7d47d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU encontrada:\n",
            "/device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AQzFg2dnHAVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <device_launch_parameters.h>\n",
        "#include <iostream>\n",
        "\n",
        "//Tener en cuenta que instalamos lo necesario para correr codigo c en colab\n",
        "//Por ello es necesario %%cu\n",
        "\n",
        "\n",
        "//El kernel suma los elementos correspondientes de los vectores\n",
        "__global__ void vectorAddKernel(const float* A, const float* B, float* C, int n)\n",
        "{\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    //garantizamos que cada thread proceso solo elementos validos del vetcor\n",
        "    if (i < n) {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "void vecAdd(float* A, float* B, float* C, int n)\n",
        "{\n",
        "    int size = n * sizeof(float);\n",
        "    float *d_A, *d_B, *d_C;\n",
        "\n",
        "    // Registramos memoria para A, B, y C\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "    cudaMalloc((void**)&d_C, size);\n",
        "\n",
        "    // Copy A and B to device memory\n",
        "    cudaMemcpy(d_A, A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define grid and block dimensions\n",
        "    int threadsPerBlock = 256;  // You can adjust this based on your GPU\n",
        "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    // Kernel launch code – to have the device perform the actual vector addition\n",
        "    vectorAddKernel<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, n);\n",
        "\n",
        "    // Copy C from the device memory\n",
        "    cudaMemcpy(C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Free device vectors\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    //Agregamos el tamaño de vector para ver los cambios en la RAM de la GPU\n",
        "    int n = 501020000;\n",
        "    float *A, *B, *C;\n",
        "\n",
        "    //\n",
        "    A = (float*)malloc(n * sizeof(float));\n",
        "    B = (float*)malloc(n * sizeof(float));\n",
        "    C = (float*)malloc(n * sizeof(float));\n",
        "h\n",
        "    // Inicializa los vectores A y B\n",
        "    // Valor del primer vector sera el doble de segundo vector\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        A[i] = static_cast<float>(i);\n",
        "        B[i] = static_cast<float>(2 * i);\n",
        "    }\n",
        "\n",
        "    vecAdd(A, B, C, n);\n",
        "\n",
        "    // Imprime los vectores A, B y el resultado C\n",
        "    std::cout << \"Vector A: \";\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        std::cout << A[i] << \" \";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    std::cout << \"Vector B: \";\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        std::cout << B[i] << \" \";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    std::cout << \"Resultado C: \";\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        std::cout << C[i] << \" \";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "\n",
        "\n",
        "\n",
        "    // C now contains the result of the vector addition\n",
        "\n",
        "    // Don't forget to free host memory when you're done\n",
        "    free(A);\n",
        "    free(B);\n",
        "    free(C);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a83a502-02c2-40eb-b2a0-3ed79e29d39c",
        "id": "XFMECSJSHzGU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Cell magic `%%cu` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IhP6Vj3SFTA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section Chapter 3"
      ],
      "metadata": {
        "id": "_PpL8NVWFaqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -o imagen.jpg https://www.24horas.cl/24horas/site/artic/20220910/imag/foto_0000000220220910153604/gatito.jpg"
      ],
      "metadata": {
        "id": "opyiSAx3FgKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "!pip install opencv-python-headless\n",
        "!apt-get -qq install -y libopencv-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCNAPE_pF83T",
        "outputId": "1718b115-a16c-4d51-e18f-6b0aa8aec61f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.8.1.78)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.23.5)\n",
            "E: Command line option '�' [from -y libopencv-dev] is not understood in combination with the other options.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile my_main.cu\n",
        "#include <iostream>\n",
        "#include <opencv2/opencv.hpp>\n",
        "\n",
        "__global__ void colorToGreyscaleConversion(unsigned char *Pout, unsigned char *Pin, int width, int height) {\n",
        "    int Col = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int Row = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    if (Col < width && Row < height) {\n",
        "        // get 1D coordinate for the grayscale image\n",
        "        int grayOffset = Row * width + Col;\n",
        "        // one can think of the RGB image having\n",
        "        // CHANNEL times columns than the grayscale image\n",
        "        int rgbOffset = grayOffset * 3; // Assuming 3 channels for RGB\n",
        "        unsigned char r = Pin[rgbOffset];     // red value for pixel\n",
        "        unsigned char g = Pin[rgbOffset + 1]; // green value for pixel\n",
        "        unsigned char b = Pin[rgbOffset + 2]; // blue value for pixel\n",
        "        // perform the rescaling and store it\n",
        "        // We multiply by floating point constants\n",
        "        Pout[grayOffset] = 0.21f * r + 0.71f * g + 0.07f * b;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    cv::Mat Imagen = cv::imread(\"/content/gatito.jpg\");  // Replace with the actual path\n",
        "\n",
        "    if (Imagen.empty()) {\n",
        "        std::cerr << \"Error: Unable to load the image.\" << std::endl;\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    const int width = Imagen.cols;\n",
        "    const int height = Imagen.rows;\n",
        "    const dim3 blockSize(16, 16);\n",
        "    const dim3 gridSize((width + blockSize.x - 1) / blockSize.x, (height + blockSize.y - 1) / blockSize.y);\n",
        "\n",
        "    unsigned char *d_input, *d_output;\n",
        "    cudaMalloc(&d_input, width * height * 3 * sizeof(unsigned char));\n",
        "    cudaMalloc(&d_output, width * height * sizeof(unsigned char));\n",
        "\n",
        "    cudaMemcpy(d_input, Imagen.data, width * height * 3 * sizeof(unsigned char), cudaMemcpyHostToDevice);\n",
        "\n",
        "    colorToGreyscaleConversion<<<gridSize, blockSize>>>(d_output, d_input, width, height);\n",
        "\n",
        "    unsigned char *outputData = new unsigned char[width * height];\n",
        "    cudaMemcpy(outputData, d_output, width * height * sizeof(unsigned char), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cv::Mat outputImage(height, width, CV_8U, outputData);\n",
        "    cv::imwrite(\"/content/gatitoblancoynegro.png\", outputImage);\n",
        "    cv::waitKey(0);\n",
        "\n",
        "\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf7CTlSXGSCF",
        "outputId": "7790ce94-ad42-4498-ac58-dcfdb778206a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing my_main.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o main my_main.cu -I/usr/include/opencv4 -L/usr/lib/x86_64-linux-gnu -lopencv_core -lopencv_highgui -lopencv_imgcodecs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sTgw9f3GXWC",
        "outputId": "dd292b71-335e-4832-e41f-bbb92f581fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/warpers.hpp(235)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::PlaneWarper::buildMaps\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::AffineWarper\"\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/warpers.hpp(235)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::PlaneWarper::warp\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::AffineWarper\"\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/blenders.hpp(100)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::Blender::prepare\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::FeatherBlender\"\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/blenders.hpp(127)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::Blender::prepare\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::MultiBandBlender\"\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/warpers.hpp(235)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::PlaneWarper::buildMaps\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::AffineWarper\"\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/warpers.hpp(235)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::PlaneWarper::warp\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::AffineWarper\"\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/blenders.hpp(100)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::Blender::prepare\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::FeatherBlender\"\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/blenders.hpp(127)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::Blender::prepare\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::MultiBandBlender\"\u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./main"
      ],
      "metadata": {
        "id": "C3KDCRBGG0wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile my_main2.cu\n",
        "#include <iostream>\n",
        "#include <opencv2/opencv.hpp>\n",
        "\n",
        "#define BLUR_SIZE 10\n",
        "\n",
        "__global__ void blurkernel(unsigned char *in, unsigned char *out, int w, int h, int channels) {\n",
        "    int Col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int Row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if (Col < w && Row < h) {\n",
        "        int pixelIdx = (Row * w + Col) * channels;\n",
        "\n",
        "        for (int k = 0; k < channels; k++) {\n",
        "            int pixVal = 0;\n",
        "            int pixels = 0;\n",
        "\n",
        "            // Obtener el promedio de la caja circundante BLUR_SIZE × BLUR_SIZE\n",
        "            for (int blurRow = -BLUR_SIZE; blurRow < BLUR_SIZE + 1; ++blurRow) {\n",
        "                for (int blurCol = -BLUR_SIZE; blurCol < BLUR_SIZE + 1; ++blurCol) {\n",
        "                    int curRow = Row + blurRow;\n",
        "                    int curCol = Col + blurCol;\n",
        "\n",
        "                    // Verificar que tengamos un píxel de imagen válido\n",
        "                    if (curRow > -1 && curRow < h && curCol > -1 && curCol < w) {\n",
        "                        int curPixelIdx = (curRow * w + curCol) * channels;\n",
        "                        pixVal += in[curPixelIdx + k];\n",
        "                        pixels++; // Realizar un seguimiento del número de píxeles en el promedio\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "\n",
        "            // Escribir nuestro nuevo valor de píxel\n",
        "            out[pixelIdx + k] = (unsigned char)(pixVal / pixels);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    cv::Mat Imagen = cv::imread(\"/content/gatito.jpg\");  // Reemplaza con la ruta correcta\n",
        "\n",
        "    if (Imagen.empty()) {\n",
        "        std::cerr << \"Error: No se puede cargar la imagen.\" << std::endl;\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    const int width = Imagen.cols;\n",
        "    const int height = Imagen.rows;\n",
        "    const dim3 blockSize(16, 16, 1);\n",
        "    const dim3 gridSize((width + blockSize.x - 1) / blockSize.x, (height + blockSize.y - 1) / blockSize.y);\n",
        "\n",
        "    unsigned char *d_input, *d_output;\n",
        "    cudaMalloc(&d_input, width * height * 3 * sizeof(unsigned char));\n",
        "    cudaMalloc(&d_output, width * height * 3 * sizeof(unsigned char));\n",
        "\n",
        "    cudaMemcpy(d_input, Imagen.data, width * height * 3 * sizeof(unsigned char), cudaMemcpyHostToDevice);\n",
        "\n",
        "    blurkernel<<<gridSize, blockSize>>>(d_input, d_output, width, height, 3);\n",
        "\n",
        "    unsigned char *outputData = new unsigned char[width * height * 3];\n",
        "    cudaMemcpy(outputData, d_output, width * height * 3 * sizeof(unsigned char), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cv::Mat outputImage(height, width, CV_8UC3, outputData);\n",
        "    cv::imwrite(\"/content/gatitoborroso.png\", outputImage);\n",
        "\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uzlN7S_JyVG",
        "outputId": "2ffaf0b7-c223-44a9-dd2f-d493104ed997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting my_main2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o main my_main2.cu -I/usr/include/opencv4 -L/usr/lib/x86_64-linux-gnu -lopencv_core -lopencv_highgui -lopencv_imgcodecs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZGjxtt6J2lu",
        "outputId": "4b1f4517-26f4-4b97-a717-e71e46ecaf1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/warpers.hpp(235)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::PlaneWarper::buildMaps\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::AffineWarper\"\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/warpers.hpp(235)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::PlaneWarper::warp\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::AffineWarper\"\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/blenders.hpp(100)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::Blender::prepare\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::FeatherBlender\"\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/blenders.hpp(127)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::Blender::prepare\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::MultiBandBlender\"\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/warpers.hpp(235)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::PlaneWarper::buildMaps\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::AffineWarper\"\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/warpers.hpp(235)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::PlaneWarper::warp\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::AffineWarper\"\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/blenders.hpp(100)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::Blender::prepare\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::FeatherBlender\"\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/blenders.hpp(127)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::Blender::prepare\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::MultiBandBlender\"\u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./main"
      ],
      "metadata": {
        "id": "sqdbI8pxO8a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section Chapter 4"
      ],
      "metadata": {
        "id": "NeGOkTKNEEwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile my_main.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Kernel para la multiplicación de matrices\n",
        "__global__ void MatrixMulKernel(float* M, float* N, float* P, int Width) {\n",
        "    // Calcular el índice de fila del elemento P y M\n",
        "    int Row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    // Calcular el índice de columna de P y N\n",
        "    int Col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if ((Row < Width) && (Col < Width)) {\n",
        "        float Pvalue = 0;\n",
        "\n",
        "        // Cada hilo calcula un elemento de la submatriz del bloque\n",
        "        for (int k = 0; k < Width; ++k) {\n",
        "            Pvalue += M[Row * Width + k] * N[k * Width + Col];\n",
        "        }\n",
        "\n",
        "        P[Row * Width + Col] = Pvalue;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Definir el tamaño de las matrices\n",
        "    const int Width = 256;\n",
        "\n",
        "    // Inicializar matrices de entrada y salida en la CPU\n",
        "    float hostM[Width * Width];\n",
        "    float hostN[Width * Width];\n",
        "    float hostP[Width * Width];\n",
        "\n",
        "    // Inicializar matrices con datos de ejemplo\n",
        "    for (int i = 0; i < Width * Width; ++i) {\n",
        "        hostM[i] = i;\n",
        "        hostN[i] = i * 2;\n",
        "    }\n",
        "\n",
        "    // Copiar matrices de la CPU a la GPU\n",
        "    float *deviceM, *deviceN, *deviceP;\n",
        "    cudaMalloc((void**)&deviceM, Width * Width * sizeof(float));\n",
        "    cudaMalloc((void**)&deviceN, Width * Width * sizeof(float));\n",
        "    cudaMalloc((void**)&deviceP, Width * Width * sizeof(float));\n",
        "\n",
        "    cudaMemcpy(deviceM, hostM, Width * Width * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(deviceN, hostN, Width * Width * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Configurar la cuadrícula y los bloques de hilos\n",
        "    dim3 dimGrid(1, 1, 1);\n",
        "    dim3 dimBlock(Width, Width, 1);\n",
        "\n",
        "    // Medir el tiempo de compilación\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Iniciar el temporizador\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    // Llamar al kernel de multiplicación de matrices\n",
        "    MatrixMulKernel<<<dimGrid, dimBlock>>>(deviceM, deviceN, deviceP, Width);\n",
        "\n",
        "    // Detener el temporizador\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    std::cout << \"Tiempo de compilación del kernel: \" << milliseconds << \" ms\" << std::endl;\n",
        "\n",
        "    // Copiar la matriz de salida desde la GPU a la CPU\n",
        "    cudaMemcpy(hostP, deviceP, Width * Width * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Imprimir la matriz de salida\n",
        "    /*\n",
        "    std::cout << \"Matriz de salida (P):\" << std::endl;\n",
        "    for (int i = 0; i < Width; ++i) {\n",
        "        for (int j = 0; j < Width; ++j) {\n",
        "            std::cout << hostP[i * Width + j] << \" \";\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }*/\n",
        "\n",
        "    // Liberar memoria en la GPU\n",
        "    cudaFree(deviceM);\n",
        "    cudaFree(deviceN);\n",
        "    cudaFree(deviceP);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzL9GXGKEfnz",
        "outputId": "3f31d252-eaae-44b5-b156-4a06b7ee8df8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting my_main.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o my_main my_main.cu"
      ],
      "metadata": {
        "id": "urEJTZynEgcc"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./my_main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dE_wf8-sFTPy",
        "outputId": "612a192c-3ed9-4083-a0a4-ac78cb8abb53"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de compilación del kernel: 0.00288 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile my_main.cu\n",
        "#include <iostream>\n",
        "#include <cstdlib>\n",
        "#include <ctime>\n",
        "\n",
        "// Define TILE_WIDTH\n",
        "#define TILE_WIDTH 32 // Tamaño del bloque de hilo (puedes ajustarlo según sea necesario)\n",
        "\n",
        "// Kernel de multiplicación de matrices con memoria compartida\n",
        "__global__ void MatrixMulKernel(float* d_M, float* d_N, float* d_P, int Width) {\n",
        "    __shared__ float Mds[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ float Nds[TILE_WIDTH][TILE_WIDTH];\n",
        "    int bx = blockIdx.x;\n",
        "    int by = blockIdx.y;\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "    int Row = by * TILE_WIDTH + ty;\n",
        "    int Col = bx * TILE_WIDTH + tx;\n",
        "    float Pvalue = 0;\n",
        "\n",
        "    for (int ph = 0; ph < Width / TILE_WIDTH; ++ph) {\n",
        "        Mds[ty][tx] = d_M[Row * Width + ph * TILE_WIDTH + tx];\n",
        "        Nds[ty][tx] = d_N[(ph * TILE_WIDTH + ty) * Width + Col];\n",
        "        __syncthreads();\n",
        "\n",
        "        for (int k = 0; k < TILE_WIDTH; ++k) {\n",
        "            Pvalue += Mds[ty][k] * Nds[k][tx];\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    d_P[Row * Width + Col] = Pvalue;\n",
        "}\n",
        "\n",
        "\n",
        "// Function to initialize matrices with random values\n",
        "void initializeMatrix(float* matrix, int size) {\n",
        "    for (int i = 0; i < size; ++i) {\n",
        "        matrix[i] = static_cast<float>(rand()) / RAND_MAX; // Random values between 0 and 1\n",
        "    }\n",
        "}\n",
        "\n",
        "// Function to print a matrix\n",
        "void printMatrix(const float* matrix, int rows, int cols) {\n",
        "    for (int i = 0; i < rows; ++i) {\n",
        "        for (int j = 0; j < cols; ++j) {\n",
        "            std::cout << matrix[i * cols + j] << \" \";\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Matrix dimensions\n",
        "    const int Width = 2048;\n",
        "    const int MatrixSize = Width * Width;\n",
        "\n",
        "    // Host matrices\n",
        "    float *h_M = new float[MatrixSize];\n",
        "    float *h_N = new float[MatrixSize];\n",
        "    float *h_P = new float[MatrixSize];\n",
        "\n",
        "    // Initialize matrices\n",
        "    initializeMatrix(h_M, MatrixSize);\n",
        "    initializeMatrix(h_N, MatrixSize);\n",
        "\n",
        "    // Device matrices\n",
        "    float *d_M, *d_N, *d_P;\n",
        "    cudaMalloc((void**)&d_M, MatrixSize * sizeof(float));\n",
        "    cudaMalloc((void**)&d_N, MatrixSize * sizeof(float));\n",
        "    cudaMalloc((void**)&d_P, MatrixSize * sizeof(float));\n",
        "\n",
        "    // Copy matrices from host to device\n",
        "    cudaMemcpy(d_M, h_M, MatrixSize * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_N, h_N, MatrixSize * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Configure grid and block dimensions\n",
        "    dim3 dimGrid(Width / TILE_WIDTH, Width / TILE_WIDTH, 1);\n",
        "    dim3 dimBlock(TILE_WIDTH, TILE_WIDTH, 1);\n",
        "\n",
        "    // Measure execution time\n",
        "    clock_t start_time = clock();\n",
        "\n",
        "    // Call the kernel\n",
        "    MatrixMulKernel<<<dimGrid, dimBlock>>>(d_M, d_N, d_P, Width);\n",
        "\n",
        "    // Synchronize to wait for the kernel to finish\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Measure execution time\n",
        "    clock_t end_time = clock();\n",
        "    double elapsed_time = static_cast<double>(end_time - start_time) / CLOCKS_PER_SEC;\n",
        "\n",
        "    std::cout << \"Matrix multiplication took \" << elapsed_time << \" seconds.\" << std::endl;\n",
        "\n",
        "    // Copy the result back from the device to the host\n",
        "    cudaMemcpy(h_P, d_P, MatrixSize * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print the result (if the matrix is small)\n",
        "    if (Width <= 16) {\n",
        "        std::cout << \"Result Matrix:\" << std::endl;\n",
        "        printMatrix(h_P, Width, Width);\n",
        "    }\n",
        "\n",
        "    // Free allocated memory\n",
        "    delete[] h_M;\n",
        "    delete[] h_N;\n",
        "    delete[] h_P;\n",
        "    cudaFree(d_M);\n",
        "    cudaFree(d_N);\n",
        "    cudaFree(d_P);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKUJ9hnbGkEb",
        "outputId": "ddf7884e-9cba-4e64-d50f-834bf9ef8404"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting my_main.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o my_main my_main.cu"
      ],
      "metadata": {
        "id": "Xhh7briEGqxp"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./my_main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AC5jZCUGu0g",
        "outputId": "1b0629f7-668f-4db6-a8f6-02d3844c1b39"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix multiplication took 0.04169 seconds.\n"
          ]
        }
      ]
    }
  ]
}